---
title:          "PRSTA: TD 3"
date:           2021-10-14 14:00
categories:     [Image S9, PRSTA]
tags:           [Image, S9, PRSTA]
math: true
---
Lien de la [note Hackmd](https://hackmd.io/@lemasymasa/ryi1R9rHK)

# Feuille 3 Exercice 1

La variable aleatoire $X$ suit une loi $N(0, \sigma^2)$ avec $\sigma \gt 0$.
Nous etudierons le test $H_0 : \sigma^2 = \sigma^2_0$ contre $H_1 : \sigma^2 = \sigma_2^1$ avec $0 \lt \sigma_0 \lt \sigma_1$.
1. Determiner la statistique de Neyman-Pearson que nous noterons $T_n$.
2. Determiner $\alpha$ en fonction du seuil du test.
3. Determiner $\beta$ en fonction du seuil du test.
4. Determiner les courbes COR associees a ce test.

<details markdown="1"><summary>Solution</summary>

$$
\begin{aligned}
T&=\frac{\Pi_{i=1}^nf(X_i,\sigma_1)}{\Pi_{i=1}^nf(X_i,\sigma_0)}\\
&= \frac{\Pi_{i=1}^n\frac{1}{\sigma_1\sqrt{2\pi}}\exp(\frac{-X_i^2}{2\sigma_1^2})}{\Pi_{i=1}^n\frac{1}{\sigma_0\sqrt{2\pi}}\exp(\frac{-X_i^2}{2\sigma_0^2})}\\
&=(\frac{\sigma_0}{\sigma_1})^n\exp(-\frac{1}{2}\sum_{i=1}^nX_i^2(\frac{1}{\sigma_1^2}-\frac{1}{\sigma_0^2}))
\end{aligned}\\
\begin{aligned}
\ln(T)&=\underbrace{n\ln(\frac{\sigma_0}{\sigma_1})}_{\color{green}{a}}-\frac{1}{2}\sum_{i=1}^nX_i^2\underbrace{(\frac{1}{\sigma_1^2}-\frac{1}{\sigma_0^2})}_{\color{green}{b}}\\
&= a-\frac{b}{2}\sum_{i=1}^nX_i^2
\end{aligned}
$$

D'apres le lemme de Neyman-Pearson:

L'hypothese $H_0$ est rejetee lorsque:

$$
\begin{aligned}
T&\gt C_{\alpha}\\
\ln(T)&\gt\ln(C_{\alpha})\\
a-\frac{b}{2}\sum_{i=1}^nX_i^2&\gt\ln(C_{\alpha})\\
\sum_{i=1}^nX_i^2&\gt-\frac{2}{b}(\ln(C_{\alpha}) - a)
\end{aligned}\\
\color{red}{\boxed{\sum_{i=1}^nX_i^2\gt S_{\alpha}}}\\
T_n=\sum_{i=1}^nX_i^2
$$

On cherche $\alpha$ et $\beta$:

$$
\begin{aligned}
\alpha&= P(\text{rejeter } H_0\vert H_0\text{ vraie})\\
&=P(\sum X_i^2\gt S_{\alpha}\vert\sigma=\sigma_0)\\
&=P(\frac{T_n}{\sigma_0^2}\gt\frac{S_{\alpha}}{\sigma_0^2})
\end{aligned}
$$

Les variables aleatoires sont normales centrees et independantes donc

$$
W_n:=\frac{T_n}{\sigma_0^2}\sim\chi_2(n)\\
\alpha=P(W_n\gt\frac{S_{\alpha}}{\sigma_0^2})
$$

On prend $\alpha=0.05$ et $n=33$

$$
\frac{S_{\alpha}}{\sigma_0^2}\simeq 47,40
$$

```python
chi2.ppf(0.95, 33)
chi2.isf(0.05, 33)
```

`s` comme `survie`

$$
\alpha=1-F_N\biggr(\frac{S_{\alpha}}{\sigma_0^2}\biggr)\\
F_N\biggr(\frac{S_{\alpha}}{\sigma_0^2}\biggr) = 1-\alpha\\
\frac{S_{\alpha}}{\sigma_0^2} = F_N^{-1}(1-\alpha)\\
\color{red}{\boxed{S_{\alpha}=\sigma_0^2F_N^{-1}(1-\alpha)}}
$$

$$
\begin{aligned}
\beta&=P(\text{Accepte H_0}\vert H_1\text{ vraie})\\
&= P(T_n\le S_{\alpha}\vert\sigma^2=\sigma_1^2)
\end{aligned}
$$

Sous l'hypothese $H_1$: $W_n':=\frac{T_n}{\sigma_1^2}\sim\chi^2(n)$

$$
\begin{aligned}
\beta &= P(W_n'\le\frac{S_{\alpha}}{\sigma_1^2})\\
&= F_n(\frac{S_{\alpha}}{\sigma_1^2})\\
\end{aligned}\\
\color{red}{\boxed{\beta = F_n\biggr(\frac{\sigma_0^2F_n^{-1}(1-\alpha)}{\sigma_1^2}\biggr)}}
$$

</details>

# Feuille 3 Exercice 3

La variable aleatoire $X$ suit une loi geometrique de parametre $p$. A lâ€™aide du theoreme de Wilks, ecrire la zone de rejet du test $H_0 : p = 0, 25$ contre $H_1 : p = 0, 5$.

<details markdown="1"><summary>Solution</summary>

D'apres le theoreme de Wilks,

$$
R_n=2\log(T_n)\sim\chi^2(1)\\
\{R_n\gt 3,84\}
$$

Il suffit d'expliciter en $R_n$


Il suffit d'expliciter $R_n$

$$
\begin{aligned}
T_n&=\frac{L(X_1,\dots,X_n,0.5)}{L(X_1,\dots,X_n,0.25)}\\
&= \frac{\prod_{i=1}^n0.5\times(1-0.5)^{X_i-1}}{\prod_{i=1}^n0.25\times(1-0.25)^{X_i-1}}\\
&= 2^n\times\prod_{i=1}^n\biggr(\frac{0.5}{0.75}\biggr)^{X_i-1}\\
&= 2^n\times\prod_{i=1}^n\biggr(\frac{2}{3}\biggr)\\
&= 2^n\times\biggr(\frac{2}{3}\biggr)^{\sum_{i=1}^n(X_i-1)}
\end{aligned}
$$

Passons au logarithme neperien:

$$
\ln(T_n)=n\ln(2)+\ln\biggr(\frac{2}{3}\biggr)\sum_{i=1}^n(X_i-1)\\
\begin{aligned}
R_n&=2\ln(T_n)\\
&= 2(n\ln(2)+\ln\biggr(\frac{2}{3}\biggr)\sum_{i=1}^n(X_i-1))
\end{aligned}\\
\alpha = 5\%
$$

<div class="alert alert-info" role="alert" markdown="1">
**Rappel**: $R_n$ suit asymptotiquement $\chi^2(1)$
</div>


Zone de rejet:

$$
\{R_n\gt 3,84\}
$$

On veut resoudre l'equation pour isoler $\sum_{i=1}^nX_i$

$$
\begin{aligned}
2[n\ln(2)+\ln(\frac{2}{3})\sum_{i=1}^n(X_i-1)]&\gt3.84\\
\ln(\frac{2}{3})\sum_{i=1}^n(X_i-1)&\gt\frac{3.84}{2}-\ln(2)\\
\sum_{i=1}^nX_i-n&\lt\frac{\frac{3.84}{2}-n\ln(2)}{ln(\frac{2}{3})}\quad\text{car }\ln(\frac{2}{3})\lt0\\
\frac{\sum_{i=1}^nX_i}{n}&\lt\frac{1.92-n\ln(2)}{n\ln(\frac{2}{3})} +1\\
\bar X_n&\lt\frac{1.92-n\ln(2)}{n\ln(\frac{2}{3})}+1
\end{aligned}
$$

</details>
