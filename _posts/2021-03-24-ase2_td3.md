---
title:          "ASE2: TD 3"
date:           2021-03-24 10:00
categories:     [tronc commun S8, ASE2]
tags:           [tronc commun, ASE2, S8, loi, binomial, estimateur, Fisher, FDCR, maximum de vraisemblance]
math: true
description: TD 3
---
Lien de la [note Hackmd](https://hackmd.io/@lemasymasa/SJytzuuV_)

# Exercice 12
$X_1,X_2,...,X_n$ des v.a. independantes de la loi de Poisson $\mathcal P(\lambda=1)$.
Soit $Y_n=\sum_{k=1}^nX_k$
1. Determiner $\lim_{n\to+\infty}P(Y_n\le n)$ (utiliser le TCL)
2. En deduire un equivalent simple de $\sum_{k=0}^n\frac{n^k}{n!}$ quand $n\to+\infty$

<div class="alert alert-warning" role="alert" markdown="1">
Quand on additionne des variables de Poisson independantes, on obtient une variable suivant la loi de Poisson avec comme parametre la somme de tous les parametres.
</div>

<details markdown="1">
<summary>Solution</summary>

1.

$X_1,X_2,...,X_n$ sont des v.a independantes et de meme loi, alors d'apres le TCL: $\frac{X_1+X_2+...+X_n-n}{\sqrt n}\to_{n\to+\infty}^{\mathcal L}\mathcal N(0,1)$

$$
\begin{cases}
Y_n=\sum_{i=1}^nX_i, E(Y_n)= \sum_{i=1}^nE(X_i)=\sum_{i=1}^n1=n\\
V(Y_n)=\sum_{i=1}^nV(X_i)=n\Rightarrow \sigma=\sqrt n
\end{cases}\\
\frac{Y_n-n}{\sqrt n}\to_{n\to+\infty}^L\mathcal N(0,1)\\
P(Y_n\le n)=P(\frac{Y_n-n}{\sqrt n}\le 0)=F_n(0)
$$

ou $F_n$ est la fonction de repartition de $\frac{Y_n-n}{\sqrt n}$
or $\frac{Y_n-n}{\sqrt n}\to_{n\to+\infty}^L\mathcal N(0,1)$

$$
\begin{aligned}
&\Rightarrow \lim_{n\to+\infty}P(Y_n\le n)=\lim_{n\to+\infty}F_n(0)=\Phi(0) \text{ f.d.r de } \mathcal N(0,1)\\
&\Rightarrow \lim_{n\to+\infty}P(Y_n\le n)=\frac{1}{2}
\end{aligned}
$$

2.

La somme de v.a independantes de la loi de Poisson $\mathcal P(1)$ suit une loi de Poisson $\mathcal P(n)$

$$
Y_n = \sum_{k=1}^nX_k\to\mathcal P(n)\\
P(Y_n\le n)=\sum_{k=0}^ne^{-n}\frac{n^k}{k!}=e^{-n}\sum_{k=0}^n\frac{n^k}{k!}
$$

D'apres la 1. $\lim_{n\to+\infty}e^{-n}\sum_{k=0}^n\frac{n^k}{k!}=\frac{1}{2}$

<div class="alert alert-success" role="alert" markdown="1">
Donc 

$$
\sum_{k=0}^n\frac{n^k}{k!}\sim\frac{1}{2}e^n
$$

avec $n$ grand

</div>

</details>

# Exercice 13
Une entreprise compte 300 employes, chacun d'entre eux telephone en moyenne 6 minutes par heures. Quel est le nombre de lignes que l'entreprise doit installer pour que la probabilite que toutes les lignes soient utilisees au meme instant soit au plus egale a $0,025$.

<details markdown="1">
<summary>Solution</summary>

Il faut definir 2 variables
1. $N$: nombre de lignes installees
2. $X$: nombre d'employes telephonant a un instant $t$

Il faut d'abord determiner la loi de $X$. La chance d'avoir un employe telephonant a un instant $t$, on convertit les minutes en heure: $\frac{6}{60} = \frac{1}{10}$. $X$ suit donc une loi $\mathcal B(300,\frac{1}{10})$

On cherche $N$ la probabilite $P(X\ge N)\le 0,025$

$$
\mathcal B(300,\frac{1}{10})\simeq N(30,\sqrt{27}) \text{ selon le theoreme de Moivre-Laplace}\\
U=\frac{X-30}{\sqrt{27}}\simeq\mathcal N(0,1)\\
\begin{aligned}
P(X\ge N)\le0,025&\Rightarrow P(U\ge\frac{N-30}{3\sqrt{3}})\le 0,025\\
&\Rightarrow1-\Phi(\frac{N-30+0,5}{3\sqrt 3})\le0,025\\
&\Rightarrow\Phi(\frac{N-30+0,5}{3\sqrt 3})\ge0,975=\Phi(1,96)
\end{aligned}
$$

ou $\Phi$ est la fonction de repartition de la loi $\mathcal N(0,1)$.

$$
\begin{aligned}
&\Leftrightarrow \frac{N-30+0,5}{3\sqrt 3} \ge 1,96\\
&\Leftrightarrow N\ge 3\sqrt 3\times1,96+29,5\\
&\Leftrightarrow N\gt 40
\end{aligned}
$$

<div class="alert alert-success" role="alert" markdown="1">
Il faut installer au moins 40 lignes.
</div>

</details>


# Exercice 14

On considere un echantillon $(X_1, X_2,...,X_n)$ d'une v.a. $X$.
Determiner la vraisemblance de cet echantillon dans les cas ou $X$ est distribue suivant:
1. une loi binomiale $\mathcal B(N,p)$
2. une loi de Poisson $\mathcal P(\lambda)$
3. Une loi exponentielle $\mathcal E(\lambda)$
4. Une loi normale $\mathcal N(m,\sigma)$

<details markdown="1">
<summary>Solution</summary>

$(X_1,X_2,...,X_n)$ un echantillon de $X$.

1.

$X\sim\mathcal B(N,p)$ ($\theta=p$ parametre).

$$
\begin{aligned}
L(x_1,x_2,...,x_n,p)&=\Pi_{i=1}^nP(X_i=x_i)\\
&=\Pi_{i=1}^n\binom{N}{x_i}p^{x_i}(1-p)^{N-x_i}\\
&= \Pi_{i=1}^n\frac{N!}{x_i!(N-x_i)!}p^{x_i}(1-p)^{N-x_i}
\end{aligned}
$$

<div class="alert alert-success" role="alert" markdown="1">

$$
L(x_1,x_2,...,x_n,p)=\frac{(N!)^n}{\Pi_{i=1}^nx_i!(N-x_i)!}p^{\sum_{i=1}^nx_i}(1-p)^{nN-\sum_{i=1}^nx_i}
$$

</div>

2.

$X\sim\mathcal P(\lambda)$ ($\theta=\lambda$ parametre)

$$
\begin{aligned}
L(x_1,x_2,...,x_n,\lambda)&=\Pi_{i=1}^nP(X_i=x_i)\\
&= \Pi_{i=1}^ne^{-\lambda}\frac{\lambda^{x_i}}{x_i!}=e^{-n\lambda}\frac{\lambda^{\sum_{i=1}^nx_i}}{\Pi_{i=1}^nx_i!}
\end{aligned}
$$

<div class="alert alert-success" role="alert" markdown="1">

$$
L(x_1,x_2,...,x_n,\lambda)=\frac{e^{-n\lambda}\lambda^{\sum_{i=1}^nx_i}}{\Pi_{i=1}^nx_i!}
$$

</div>

3.

$X\sim\mathcal E(\lambda)$ (exponentielle) (variable continue), $\theta=\lambda$ (parametre)

$$
L(x_1,x_2,...,x_n,\lambda)=\Pi_{i=1}^nf(x_i)=\Pi_{i=1}^n\lambda e^{-\lambda x_i}
$$

<div class="alert alert-success" role="alert" markdown="1">

$$
L(x_1,x_2,...,x_n,\lambda)=\lambda^ne^{-\lambda \sum_{i=1}^nx_i}
$$

</div>

4.

$X\sim\mathcal N(m,\sigma)$ (variable continue), parametres $m$ et $\sigma$

$$
L(x_1,x_2,...,x_n,m,\sigma)=\Pi_{i=1}^nf(x_i)\\
\text{or } f(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}(\frac{X-m}{\sigma})^2} \text{ (densite)}\\
L(x_1,x_2,...,x_n,m,\sigma)=\Pi_{i=1}^n\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}(\frac{X-m}{\sigma})^2}
$$

<div class="alert alert-success" role="alert" markdown="1">

$$
L(x_1,x_2,...,x_n,m,\sigma) = \frac{1}{(\sigma\sqrt{2\pi})^n}e^{-\frac{1}{2\sigma^2}\sum_{i=1}^n(X_i-m)^2}
$$

</div>

</details>

# Exercice 15

Soit $X$ une v.a. qui suit la loi normale centree, de variance $\sigma^2$ inconnue ($\sigma\gt0$). $\forall n\ge 2$, on dispose d'une n echantillon $(X_1,X_2,...,X_n)$ des variables independantes et de meme loi que $X$.

Soit $S_n=\frac{1}{n}\sum_{i=1}^nX_i^2$

1. Montrer que $S_n$ est un estimateur sans biais de $\sigma^2$
2. Montrer que $S_n$ converge en probabilite vers $\sigma^2$

<details markdown="1">
<summary>Solution</summary>

X v.a. normale centree $X\to\mathcal N(0,\sigma)$, $\sigma$ inconnu.

$(X_1,...,X_n)$ echantillon de $X$.

$$
S_n=\frac{1}{n}\sum_{i=1}^nX_i^2
$$

1.

$\forall i$, $X_i$ suit la loi $\mathcal N(0,\sigma)$: $V(X_i)=E(X_i^2)$ donc 

$$
\begin{aligned}
E(S_n)&=\frac{1}{n}\sum_{i=1}^nE(X_i^2)=\frac{1}{n}\sum_{i=1}^nV(X_i)\\
&=\frac{1}{n}\sum_{i=1}^n\sigma^2=\frac{n\sigma^2}{n}\\
&=\sigma^2 \text{ (sans biais)}
\end{aligned}
$$

2.

*Convergence de $Sn$?*

$$
\begin{aligned}
V(S_n) &= \frac{1}{n^2}\sum_{i=1}^nV(X_i^2)=\frac{n}{n^2}V(X^2)\\
&= \frac{V(X^2)}{n}=\frac{c}{n} \quad (C=V(X^2))\\
&\Rightarrow V(S_n)\to_{n\to+\infty}0
\end{aligned}
$$

D'apres l'inegalite de Tchebychev:

$$
\begin{aligned}
\forall \varepsilon, &P(\vert S_n-E(S_n)\vert\ge \varepsilon)\le\frac{V(S_n)}{\varepsilon^2}\\
\Rightarrow &P(\vert S_n-E(S_n)\vert \ge\varepsilon)\le\frac{c}{n\varepsilon^2}\to_{n\to+\infty}0
\end{aligned}
$$

<div class="alert alert-success" role="alert" markdown="1">
Donc:

$$
S_n\to_{n\to+\infty}^P\sigma^2
$$

</div>

</details>
