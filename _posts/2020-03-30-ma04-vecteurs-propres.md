---
title:          "CAMA : ma04 Vecteurs propres"
date:           2020-03-30 10:00
categories:     [S6, Shannon, CAMA]
tags:           [S6, CAMA, Shannon]
math: true
description: Vecteurs propres
---
Lien de la [note Hackmd](https://hackmd.io/@lemasymasa/HkSoByuhU)
# Cours du 30 / 03

Soit A une matrice qui repr√©sente une application lin√©aire quelconque. Que se passe-t-il si on l'applique $n$ fois ?
![](https://i.imgur.com/Nv1qhKD.png)
```
array([[ 0.707,  0.966,  0.966,  0.707,  0.259, -0.259, -0.707, -1.061, -1.414, -1.061, -0.707, -0.   ,  0.707],
       [-0.707, -0.259,  0.259,  0.707,  0.966,  0.966,  0.707,  0.354,  0.   , -0.354, -0.707, -0.707, -0.707]])
```
``` python
# on prend une matrice de transformation au hasard (donc probablement pas orthoganale)
A = np.array([[3,2], [1,2]])
```
``` python
as1 = np.dot(A, mouse)
as2 = 3 * A @ mouse # souris 3 fois plus grande
```
![](https://i.imgur.com/ATVie90.png)
<div class="alert alert-info" role="alert" markdown="1">
La transformation n'est pas une isom√©trie donc la matrice n'est pas orthogonale.
</div>
<div class="alert alert-warning" role="alert" markdown="1">
La souris 3x plus grande est isom√©trique car $A$ est une application lin√©aire.
</div>
``` python
aas1 = A @ A @ mouse
aaas1 = A @ A @ A @ mouse
```
![](https://i.imgur.com/wf9vAdY.png)
La figure s'√©tire suivant le vecteur $(2, 1)$
<div class="alert alert-warning" role="alert" markdown="1">
Si $A{\bf x}$ fait tourner la souris d'environ 25¬∞, appliquer 2 ou 3 fois $A$ ne fait plus tourner la figure.
</div>

## Vecteurs propres et valeurs propres
<div class="alert alert-danger" role="alert" markdown="1">
Les valeurs et vecteurs propres respectent cette priopri√©t√© : 
$$ 
A \, {\bf v_i} = \lambda_i \, {\bf v_i} 
$$
* $(\lambda_i, {\bf v_i})$ : couple valeur / vecteur propres
</div>

``` python
val_propre, vec_propre = lin.eig(A)
```
```
Valeurs propres de A : [4.+0.j 1.+0.j] 

Vecteurs propres de A (chaque vecteur propre est √©crit verticalement):
 [[ 0.894 -0.707]
 [ 0.447  0.707]]
```

<div class="alert alert-danger" role="alert" markdown="1">
Les vecteurs propres sont des **attracteurs** qui capturent tous les points si on fait un nombre infini de multiplications par $A$.
Les points **s'alignent** sur l'un des deux vecteurs propres.
</div>

``` python
N = 100
cercle = np.array([[np.cos(i * 2*np.pi/N), np.sin(i * 2*np.pi/N)] for i in range(N)]).T
a10c = np.array([x for x in (A10 @ cercle).T]).T
a10cn = np.array([x/lin.norm(x) for x in a10c.T]).T  # a10c norm√©
nb1 = np.sum([lin.norm(a10cn[:,i] - vec_propre[:,0]) < 0.01 for i in range(N)])   \
      + np.sum([lin.norm(a10cn[:,i] + vec_propre[:,0]) < 0.01 for i in range(N)])
nb2 = np.sum([lin.norm(a10cn[:,i] - vec_propre[:,1]) < 0.01 for i in range(N)])   \
      + np.sum([lin.norm(a10cn[:,i] + vec_propre[:,1]) < 0.01 for i in range(N)])
```

```
Nombre de points proche du 1er vecteur propre :  100
Nombre de points proche du 2e  vecteur propre :  0
```
Seuls les points colin√©aires au second vecteur propre le resteront, les autres rejoignent le premier vecteur propre.

## Le cas des matrices de rotation
*Quels sont les vecteurs propres d'une matrice de rotation ?*
``` python
def Rot(Œ∏):
    return np.array([[np.cos(Œ∏), -np.sin(Œ∏)], [np.sin(Œ∏), np.cos(Œ∏)]])

R = Rot(2*np.pi/10)

R_valp, R_vecp = lin.eig(R)
```
```
Valeurs propres de R : [0.809+0.588j 0.809-0.588j] 

Vecteurs propres de R :
 [[0.707+0.j    0.707-0.j   ]
 [0.   -0.707j 0.   +0.707j]]
```
``` python
# regardons un autre angle
R = Rot(2*np.pi/3)

R_valp, R_vecp = lin.eig(R)
```
```
Valeurs propres de R : [-0.5+0.866j -0.5-0.866j] 

Vecteurs propres de R :
 [[ 0.-0.707j  0.+0.707j]
 [-0.707+0.j    -0.707-0.j]]
```
<div class="alert alert-info" role="alert" markdown="1">
* Les valeurs et vecteurs propres sont des complexes
* Les valeurs propres ont la m√™me norme
</div>

## Sym√©trie axiale horizontale
$$
Sx = 
\begin{bmatrix}
1 & 0 \\
0 & -1  \\
\end{bmatrix}
$$

``` python
Sx = np.array([[1, 0], [0, -1]])

Sx_valp, Sx_vecp = lin.eig(Sx)
```
```
Valeurs propres de Sx : [ 1.+0.j -1.+0.j] 

Vecteurs propres de Sx :
 [[1. 0.]
 [0. 1.]]
```

* Une matrice diagonale modifie que la i-i√®me coordonn√©ee de ${\bf x}$ par la i-i√®me valeur de sa diagonale.
* Ses vecteurs propres sont ceux de la base d'origine : 

``` python
D = np.diag(np.random.randint(10,size=5))
D_valp, D_vecp = lin.eig(D)
```
```
Valeurs propres de D : [8.+0.j 8.+0.j 4.+0.j 7.+0.j 1.+0.j] 

Vecteurs propres de D :
 [[1. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0.]
 [0. 0. 1. 0. 0.]
 [0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 1.]]
```

## Diagonalisation d'une matrice

<div class="alert alert-danger" role="alert" markdown="1">
En changeant de rep√®re, on peut repr√©senter une application lin√©aire par une matrice diagonale contenant ses valeurs propres.
$$
\exists P \; / \; A = P\, \Lambda \, P^{-1} \quad
$$
* avec $\Lambda$ la matrice diagonale des valeurs propres $\lambda_i$
* P matrice de passage : vecteurs propres
</div>

``` python
A
vec_propre @ np.diag(val_propre) @ lin.inv(vec_propre)
```
```
A :
 [[3 2]
 [1 2]] 

ùëÉ Œõ inv(ùëÉ) :
 [[3.+0.j 2.+0.j]
 [1.+0.j 2.+0.j]
```
* **Matrice inversible :** si une des valeurs propre est nulle alors $\Lambda$ n'est pas inversible et donc A n'est pas inversible
* **Matrice non diagonalisable :** si l'ensemble des vecteurs propres ne genere pas un espace de meme dimension que d'origine, alors on ne peut pas diagonaliser la matrice